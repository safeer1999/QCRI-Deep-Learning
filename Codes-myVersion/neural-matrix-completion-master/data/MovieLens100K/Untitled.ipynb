{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/melshrif/Documents/Matrix Completion Project/neural-matrix-completion-master/data/MovieLens100K'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.sparse\n",
    "import random\n",
    "import sys\n",
    "import time \n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, data_dir):\n",
    "        ''' data_dir: dataset directory\n",
    "            N: number of rows\n",
    "            M: number of columns\n",
    "        '''\n",
    "        self.data_dir = data_dir\n",
    "        self.rating_fname = data_dir + 'rating.npz'\n",
    "        self.tr_m_fname = data_dir + 'train_mask.npz'\n",
    "        self.v_m_fname = data_dir + 'val_mask.npz'\n",
    "        self.n_X = 0\n",
    "        self.n_Y = 0\n",
    "        self.R = None\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.max_val = None\n",
    "        self.min_val = None\n",
    "        self.train_mask = None\n",
    "        self.val_mask = None\n",
    "        self.current_X_tr_ind = 0\n",
    "        self.current_Y_tr_ind = 0\n",
    "        self.current_X_val_ind = 0\n",
    "        self.current_Y_val_ind = 0\n",
    "\n",
    "    def load_data(self):\n",
    "        self.R = scipy.sparse.load_npz(self.rating_fname)\n",
    "        self.N, self.M = self.R.shape\n",
    "        print('Original data: %d x %d' %(self.R.shape[0], self.R.shape[1]))\n",
    "        val_set = np.unique(self.R.data)\n",
    "        self.min_val = float(val_set[0]) \n",
    "        self.max_val = float(val_set[-1])\n",
    "        self.train_mask = scipy.sparse.load_npz(self.tr_m_fname).astype(np.float32)\n",
    "        self.val_mask = scipy.sparse.load_npz(self.v_m_fname).astype(np.float32)\n",
    "        print('Finished loading data')\n",
    "        self.X_tr_indices = np.arange(self.N)\n",
    "        self.Y_tr_indices = np.arange(self.M)\n",
    "        self.X_val_indices = np.arange(self.N)\n",
    "        self.Y_val_indices = np.arange(self.M)\n",
    "        print('Finished initializing indices')\n",
    "\n",
    "    def split(self):\n",
    "        self.R_tr_unnormalized = self.R.multiply(self.train_mask)  \n",
    "        self.R_val_unnormalized = self.R.multiply(self.val_mask)\n",
    "        self.X_tr = self.R_tr_unnormalized.copy()\n",
    "        self.Y_tr = self.R_tr_unnormalized.copy().T.tocsr()\n",
    "\n",
    "    def shuffle_indices(self, for_x=False, for_y=False):\n",
    "        if for_x:\n",
    "            print('Shuffle train X indices')\n",
    "            self.X_tr_indices = np.random.permutation(range(self.N))\n",
    "        if for_y:\n",
    "            print('Shuffle train Y indices')\n",
    "            self.Y_tr_indices = np.random.permutation(range(self.M))\n",
    "\n",
    "    def get_num_samples(self, dataset):\n",
    "        if dataset == 'train':\n",
    "            return self.x_train.shape[0]\n",
    "        if dataset == 'val':\n",
    "            return self.x_val.shape[0]\n",
    "\n",
    "    def get_X_dim(self):\n",
    "        return self.X_tr.shape[1]\n",
    "\n",
    "    def get_Y_dim(self):\n",
    "        return self.Y_tr.shape[1]\n",
    "\n",
    "    def next_full_batch(self, dataset):\n",
    "        X_set = None\n",
    "        Y_set = None\n",
    "        mask = None\n",
    "        X_set = self.X_tr\n",
    "        Y_set = self.Y_tr\n",
    "        if dataset == 'train':\n",
    "            mask = self.train_mask\n",
    "        elif dataset == 'val':\n",
    "            mask = self.val_mask\n",
    "        R = X_set\n",
    "        return X_set, Y_set, R, mask.astype(np.float32), True\n",
    "\n",
    "    def get_toread_indices(self, current, all_indices, batch_size):\n",
    "        ''' Get indices of samples to-be-read from all_indices\n",
    "        '''\n",
    "        start = current\n",
    "        end = current + batch_size\n",
    "        n_samples = all_indices.shape[0]\n",
    "        to_read = 0\n",
    "        flag = False\n",
    "        if end > n_samples:\n",
    "            to_read = end - n_samples\n",
    "            end = n_samples\n",
    "            flag = True\n",
    "        to_read_indices = all_indices[start:end]\n",
    "        start = end   \n",
    "        if to_read > 0:\n",
    "            to_read_indices = np.append(to_read_indices, all_indices[0:to_read])     \n",
    "            start = 0\n",
    "        return to_read_indices, start, flag\n",
    "\n",
    "    def get_elements(self, R, x_indices, y_indices):\n",
    "        ''' get values of all pairs of selected rows and columns '''\n",
    "        n = x_indices.shape[0]\n",
    "        m = y_indices.shape[0]\n",
    "        values = np.zeros((n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                values[i,j] = R[x_indices[i],y_indices[j]]\n",
    "        return values\n",
    "\n",
    "    def get_elements_vectorized(self, R, x_indices, y_indices):\n",
    "        ''' vectorized implementation of get_ratings functions. Gain 3x speedup '''\n",
    "        n = x_indices.shape[0]\n",
    "        m = y_indices.shape[0]\n",
    "        values = np.zeros((n,m)).astype(np.float32)\n",
    "        value_ind1, value_ind2 = np.meshgrid(x_indices, y_indices)\n",
    "        ind1, ind2 = np.meshgrid(range(n), range(m))\n",
    "        values[ind1.flatten(),ind2.flatten()] = R[value_ind1.flatten(), value_ind2.flatten()]\n",
    "        return values\n",
    "\n",
    "    def next_batch(self, bs_x, bs_y, dataset, verbose=False):\n",
    "        ''' read next batch of input\n",
    "        '''\n",
    "        if dataset == 'train':\n",
    "            start_x = self.current_X_tr_ind\n",
    "            start_y = self.current_Y_tr_ind\n",
    "            all_x_indices = self.X_tr_indices\n",
    "            all_y_indices = self.Y_tr_indices\n",
    "            full_mask = self.train_mask\n",
    "            full_R = self.R_tr_unnormalized\n",
    "        elif dataset == 'val':\n",
    "            start_x = self.current_X_val_ind\n",
    "            start_y = self.current_Y_val_ind\n",
    "            all_x_indices = self.X_val_indices\n",
    "            all_y_indices = self.Y_val_indices\n",
    "            full_mask = self.val_mask\n",
    "            full_R = self.R_val_unnormalized\n",
    "        else:\n",
    "            assert False, 'Invalid dataset'\n",
    "        x_indices, start_x, flag_x = self.get_toread_indices(start_x, all_x_indices, bs_x)\n",
    "        y_indices, start_y, flag_y = self.get_toread_indices(start_y, all_y_indices, bs_y)\n",
    "\n",
    "        start = time.time()\n",
    "        x = self.X_tr[x_indices,:].todense()\n",
    "        y = self.Y_tr[y_indices,:].todense()\n",
    "        if verbose:\n",
    "            print('Load dense x and y takes %f s' %(time.time() - start))\n",
    "\n",
    "        R = self.get_elements_vectorized(full_R, x_indices, y_indices)\n",
    "        mask = self.get_elements_vectorized(full_mask, x_indices, y_indices)\n",
    "        \n",
    "        start = time.time()\n",
    "        # scale R to be in range [-1,1]\n",
    "        mid = (self.max_val + self.min_val) / 2\n",
    "        R = (R - mid) / (mid - self.min_val)\n",
    "\n",
    "        if dataset == 'train':\n",
    "            self.current_X_tr_ind = start_x\n",
    "            self.current_Y_tr_ind = start_y \n",
    "        elif dataset == 'val':\n",
    "            self.current_X_val_ind = start_x\n",
    "            self.current_Y_val_ind = start_y\n",
    "\n",
    "        if dataset == 'train':\n",
    "            if flag_x:\n",
    "                self.shuffle_indices(for_x=True)\n",
    "            if flag_y:\n",
    "                self.shuffle_indices(for_y=True)\n",
    "        flag = flag_x or flag_y\n",
    "        return x, y, R, mask, flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ModelConfig():\n",
    "    u_hidden_sizes = [2048,1024]    # hidden layers's size for the row branch\n",
    "    v_hidden_sizes = [2048,1024]    # hidden layers's size for the column branch\n",
    "    dropout_keep_prob = 0.1         # dropout rate = 1.0 - dropout_keep_prob\n",
    "    use_bn = True                   # use batch normalization after fully-connected layer\n",
    "    activation_fn = 'relu'          # activation function\n",
    "    summarization = False           # user summarization layers \n",
    "    n_u_summ_filters = [32]         # no. conv filters in summarization layers in the row branch\n",
    "    n_v_summ_filters = [32]         # no. conv filters in summarization layers in the column branch\n",
    "    u_summ_layer_sizes = [20]       # conv filter sizes in summarization layers in the row branch\n",
    "    v_summ_layer_sizes = [10]       # conv filter sizes in summarization layers in the column branch\n",
    "\n",
    "class TrainConfig(object):\n",
    "    \"\"\"Sets the default training hyperparameters.\"\"\"\n",
    "    batch_size_x = 100\n",
    "    batch_size_y = 170              # should be set accordingly to the ratio between row and column of the original matrix \n",
    "\n",
    "    initial_lr = 1e-2               # initial learning rate\n",
    "    lr_decay_factor = 0.65          # learning rate decay factor\n",
    "    num_epochs_per_decay = 50       # decay learning every ? epochs\n",
    "    n_epochs = 1000                 # number of training epochs (1 epoch is one round passing through all the rows or columns)\n",
    "    save_every_n_epochs = 500       # saving model every ? epochs\n",
    "    log_every_n_steps = 20          # print training log every ? steps\n",
    "\n",
    "    weight_decay = 0.0              # weight of the l2 regularization \n",
    "\n",
    "def arr_to_string(arr):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = str(arr[i])\n",
    "    return ','.join(arr)\n",
    "\n",
    "# model configs\n",
    "tf.flags.DEFINE_string('u_hidden_sizes', arr_to_string(ModelConfig.u_hidden_sizes),'')\n",
    "tf.flags.DEFINE_string('v_hidden_sizes', arr_to_string(ModelConfig.v_hidden_sizes),'')\n",
    "tf.flags.DEFINE_float('dropout_keep_prob', ModelConfig.dropout_keep_prob,'')\n",
    "tf.flags.DEFINE_boolean('use_bn', ModelConfig.use_bn,'')\n",
    "tf.flags.DEFINE_string('activation_fn', ModelConfig.activation_fn,'')\n",
    "tf.flags.DEFINE_boolean('summarization', ModelConfig.summarization,'')\n",
    "tf.flags.DEFINE_string('n_u_summ_filters', arr_to_string(ModelConfig.n_u_summ_filters),'')\n",
    "tf.flags.DEFINE_string('n_v_summ_filters', arr_to_string(ModelConfig.n_v_summ_filters),'')\n",
    "tf.flags.DEFINE_string('u_summ_layer_sizes', arr_to_string(ModelConfig.u_summ_layer_sizes),'')\n",
    "tf.flags.DEFINE_string('v_summ_layer_sizes', arr_to_string(ModelConfig.v_summ_layer_sizes),'')\n",
    "\n",
    "# training configs\n",
    "tf.flags.DEFINE_integer('batch_size_x', TrainConfig.batch_size_x,'')\n",
    "tf.flags.DEFINE_integer('batch_size_y', TrainConfig.batch_size_y,'')\n",
    "tf.flags.DEFINE_float('initial_lr', TrainConfig.initial_lr,'')\n",
    "tf.flags.DEFINE_float('lr_decay_factor', TrainConfig.lr_decay_factor,'')\n",
    "tf.flags.DEFINE_integer('num_epochs_per_decay', TrainConfig.num_epochs_per_decay,'')\n",
    "tf.flags.DEFINE_integer('n_epochs', TrainConfig.n_epochs,'')\n",
    "tf.flags.DEFINE_integer('save_every_n_epochs', TrainConfig.save_every_n_epochs,'')\n",
    "tf.flags.DEFINE_integer('log_every_n_steps', TrainConfig.log_every_n_steps,'')\n",
    "tf.flags.DEFINE_float('weight_decay', TrainConfig.weight_decay,'')\n",
    "\n",
    "CONFIGS = tf.app.flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(FLAGS.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/MovieLens100K/rating.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e3282a05c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c16ed639730b>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original data: %d x %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melshrif/anaconda/lib/python2.7/site-packages/scipy/sparse/_matrix_io.pyc\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mPICKLE_KWARGS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melshrif/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/MovieLens100K/rating.npz'"
     ]
    }
   ],
   "source": [
    "dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'configs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e5f55ac2fee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_basedir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'snapshots/snapshot'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcfgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'configs' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "# import configs.configs_ML100K as configs\n",
    "# from model import NMC\n",
    "# from data_loader import DataLoader\n",
    "import time \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"./data/MovieLens100K/\", \"Data directory.\")\n",
    "tf.flags.DEFINE_string(\"output_basedir\", \"./outputs/\", \"Directory for saving and loading model checkpoints.\")\n",
    "tf.flags.DEFINE_string(\"pretrained_fname\", \"\", \"Name of the pretrained model checkpoints (to resume from)\")\n",
    "tf.flags.DEFINE_string(\"output_dir\", \"\", \"Model output directory.\")\n",
    "FLAGS.output_dir = FLAGS.output_basedir + 'snapshots/snapshot'\n",
    "\n",
    "cfgs = configs.CONFIGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
